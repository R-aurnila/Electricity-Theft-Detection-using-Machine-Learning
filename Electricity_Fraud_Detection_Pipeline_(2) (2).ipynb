{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AIe8EnQLi_5L"
      },
      "outputs": [],
      "source": [
        "# !apt-get install p7zip-full"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)\n",
        "#!pip uninstall tensorflow -2.15.0\n",
        "#!pip install tensorflow==2.12.0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qjPAvC1Lwp1X",
        "outputId": "c6262f32-063a-455b-961f-70849e5f1298"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.12.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Axc9Ef43jH8M",
        "outputId": "14594d1c-0a5a-4d78-c5f8-eca8c4c0d0c4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.12.0\n"
          ]
        }
      ],
      "source": [
        "# !7z x data.7z\n",
        "print(tf.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mzvEI7YJe-O_"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QPy0BhToe_Xd"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, mean_absolute_error, mean_squared_error, confusion_matrix, precision_recall_fscore_support, roc_auc_score\n",
        "from tensorflow import keras\n",
        "from tensorflow.python.keras import Sequential\n",
        "from tensorflow.python.keras.layers import Dense, Conv1D, Flatten, Conv2D\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.svm import SVC\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import xgboost as xgb\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.preprocessing import MinMaxScaler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1_WksWgekRNH"
      },
      "outputs": [],
      "source": [
        "# import warnings\n",
        "\n",
        "# warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rawData = pd.read_csv('/content/drive/MyDrive/Power_Theft_Detection/Dataset/data.csv')\n",
        "# rawData = rawData.iloc[:, -30:]"
      ],
      "metadata": {
        "id": "N0o_xT6N3-lu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wIbW7fZnLnqG",
        "outputId": "52426ecc-04a6-455e-bdf6-1cf0cbe559eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rawData.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EHxNdYvq4K2Z",
        "outputId": "ea3f50ed-2b4b-4232-e02c-12736a16a954"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['CONS_NO', 'FLAG', '2014/1/1', '2014/1/10', '2014/1/11', '2014/1/12',\n",
              "       '2014/1/13', '2014/1/14', '2014/1/15', '2014/1/16',\n",
              "       ...\n",
              "       '2016/9/28', '2016/9/29', '2016/9/3', '2016/9/30', '2016/9/4',\n",
              "       '2016/9/5', '2016/9/6', '2016/9/7', '2016/9/8', '2016/9/9'],\n",
              "      dtype='object', length=1036)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PnxdoINlecvB"
      },
      "source": [
        "# Data Processing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mWLmothfdrp5",
        "outputId": "a11c571b-5a55-4dac-f569-9f0db0c17736"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "           day1      day2      day3      day4      day5      day6      day7  \\\n",
            "0      0.254098  0.631603  0.580146  0.486794  0.000000  0.140710  0.226321   \n",
            "1      0.848848  1.000000  0.503687  0.877880  0.577880  0.308295  0.345161   \n",
            "2      1.000000  0.619343  0.417855  0.528828  0.182889  0.171110  0.504030   \n",
            "3      0.424419  0.781008  0.709302  0.906977  0.750000  0.534884  0.486434   \n",
            "4      0.506466  0.086207  0.407328  0.092672  0.784483  0.196121  0.362069   \n",
            "...         ...       ...       ...       ...       ...       ...       ...   \n",
            "37119  0.672340  0.310638  1.000000  0.625532  0.140426  0.212766  0.497872   \n",
            "37120  0.211538  0.503846  0.615385  1.000000  0.219231  0.473077  0.565385   \n",
            "37121  0.661355  0.698805  0.157769  0.109960  0.002390  0.035060  0.003187   \n",
            "37122  1.000000  0.894134  0.758937  0.706233  0.486251  0.492209  0.401925   \n",
            "37123  0.668567  0.512473  0.279401  0.284391  0.395581  0.374911  0.253029   \n",
            "\n",
            "           day8      day9     day10  ...     day21     day22     day23  \\\n",
            "0      0.219490  0.289617  0.321494  ...  0.221311  0.214026  0.530965   \n",
            "1      0.355300  0.194470  0.430876  ...  0.000000  0.160829  0.243318   \n",
            "2      0.071606  0.000000  0.192498  ...  0.721637  0.262864  0.569746   \n",
            "3      0.000000  0.228682  0.437984  ...  0.476744  1.000000  0.534884   \n",
            "4      0.168103  0.340517  0.006466  ...  0.834052  0.431034  0.165948   \n",
            "...         ...       ...       ...  ...       ...       ...       ...   \n",
            "37119  0.234043  0.365957  0.127660  ...  0.595745  0.302128  0.225532   \n",
            "37120  0.350000  0.007692  0.346154  ...  0.623077  0.646154  0.496154   \n",
            "37121  0.015936  0.163347  0.225498  ...  1.000000  0.019124  0.199203   \n",
            "37122  0.000000  0.473877  0.597617  ...  0.734189  0.395967  0.802016   \n",
            "37123  0.012117  0.129722  1.000000  ...  0.000000  0.117605  0.498931   \n",
            "\n",
            "          day24     day25     day26     day27     day28     day29     day30  \n",
            "0      0.106557  1.000000  0.582423  0.965847  0.614299  0.572860  0.439891  \n",
            "1      0.557143  0.935484  0.556221  0.372811  0.291244  0.593088  0.434101  \n",
            "2      0.457533  0.378177  0.530068  0.633602  0.744575  0.761314  0.693118  \n",
            "3      0.536822  0.744186  0.556202  0.676357  0.468992  0.618217  0.422481  \n",
            "4      0.588362  0.153017  0.193966  0.021552  0.120690  0.323276  0.295259  \n",
            "...         ...       ...       ...       ...       ...       ...       ...  \n",
            "37119  0.655319  0.370213  0.391489  0.472340  0.336170  0.234043  0.651064  \n",
            "37120  0.184615  0.046154  0.534615  0.053846  0.000000  0.530769  0.311538  \n",
            "37121  0.154582  0.274104  0.307570  0.235060  0.498008  0.160956  0.058167  \n",
            "37122  0.628781  0.935380  0.595784  0.650779  0.566911  0.554079  0.466086  \n",
            "37123  0.164647  0.990021  0.658589  0.506058  0.387028  0.410549  0.503207  \n",
            "\n",
            "[37124 rows x 30 columns]\n",
            "       FLAG                           CONS_NO      day1      day2      day3  \\\n",
            "0         1  0387DD8A07E07FDA6271170F86AD9151  0.254098  0.631603  0.580146   \n",
            "1         1  B32AC8CC6D5D805AC053557AB05F5343  0.848848  1.000000  0.503687   \n",
            "2         1  EDFC78B07BA2908B3395C4EB2304665E  1.000000  0.619343  0.417855   \n",
            "3         1  6BCFD78138BC72A9BA1BFB0B79382192  0.424419  0.781008  0.709302   \n",
            "4         1  34C1954AA3703C4F8BD8EAEA7C4B7B83  0.506466  0.086207  0.407328   \n",
            "...     ...                               ...       ...       ...       ...   \n",
            "37119     0  F1472871E1AFF49D4289564B6377D76C  0.672340  0.310638  1.000000   \n",
            "37120     0  F3C8BBCD2DC26C1E0249DEEF6A4256B7  0.211538  0.503846  0.615385   \n",
            "37121     0  A9A0FE83467A680FBFB0DBFC910DF227  0.661355  0.698805  0.157769   \n",
            "37122     0  D9A6ADA018FA46A55D5438370456AA45  1.000000  0.894134  0.758937   \n",
            "37123     0  F3406636BAD1E6E0826E8EDDC9A1BF00  0.668567  0.512473  0.279401   \n",
            "\n",
            "           day4      day5      day6      day7      day8  ...     day21  \\\n",
            "0      0.486794  0.000000  0.140710  0.226321  0.219490  ...  0.221311   \n",
            "1      0.877880  0.577880  0.308295  0.345161  0.355300  ...  0.000000   \n",
            "2      0.528828  0.182889  0.171110  0.504030  0.071606  ...  0.721637   \n",
            "3      0.906977  0.750000  0.534884  0.486434  0.000000  ...  0.476744   \n",
            "4      0.092672  0.784483  0.196121  0.362069  0.168103  ...  0.834052   \n",
            "...         ...       ...       ...       ...       ...  ...       ...   \n",
            "37119  0.625532  0.140426  0.212766  0.497872  0.234043  ...  0.595745   \n",
            "37120  1.000000  0.219231  0.473077  0.565385  0.350000  ...  0.623077   \n",
            "37121  0.109960  0.002390  0.035060  0.003187  0.015936  ...  1.000000   \n",
            "37122  0.706233  0.486251  0.492209  0.401925  0.000000  ...  0.734189   \n",
            "37123  0.284391  0.395581  0.374911  0.253029  0.012117  ...  0.000000   \n",
            "\n",
            "          day22     day23     day24     day25     day26     day27     day28  \\\n",
            "0      0.214026  0.530965  0.106557  1.000000  0.582423  0.965847  0.614299   \n",
            "1      0.160829  0.243318  0.557143  0.935484  0.556221  0.372811  0.291244   \n",
            "2      0.262864  0.569746  0.457533  0.378177  0.530068  0.633602  0.744575   \n",
            "3      1.000000  0.534884  0.536822  0.744186  0.556202  0.676357  0.468992   \n",
            "4      0.431034  0.165948  0.588362  0.153017  0.193966  0.021552  0.120690   \n",
            "...         ...       ...       ...       ...       ...       ...       ...   \n",
            "37119  0.302128  0.225532  0.655319  0.370213  0.391489  0.472340  0.336170   \n",
            "37120  0.646154  0.496154  0.184615  0.046154  0.534615  0.053846  0.000000   \n",
            "37121  0.019124  0.199203  0.154582  0.274104  0.307570  0.235060  0.498008   \n",
            "37122  0.395967  0.802016  0.628781  0.935380  0.595784  0.650779  0.566911   \n",
            "37123  0.117605  0.498931  0.164647  0.990021  0.658589  0.506058  0.387028   \n",
            "\n",
            "          day29     day30  \n",
            "0      0.572860  0.439891  \n",
            "1      0.593088  0.434101  \n",
            "2      0.761314  0.693118  \n",
            "3      0.618217  0.422481  \n",
            "4      0.323276  0.295259  \n",
            "...         ...       ...  \n",
            "37119  0.234043  0.651064  \n",
            "37120  0.530769  0.311538  \n",
            "37121  0.160956  0.058167  \n",
            "37122  0.554079  0.466086  \n",
            "37123  0.410549  0.503207  \n",
            "\n",
            "[37124 rows x 32 columns]\n"
          ]
        }
      ],
      "source": [
        "rawData = pd.read_csv('/content/drive/MyDrive/Power_Theft_Detection/Dataset/data.csv')\n",
        "rawData = rawData.iloc[:, :2].join(rawData.iloc[:, -30:])\n",
        "rawData.columns.values[-30:] = [f\"day{i}\" for i in range(1, 31)]\n",
        "infoData = pd.DataFrame()\n",
        "infoData['FLAG'] = rawData['FLAG']\n",
        "infoData['CONS_NO'] = rawData['CONS_NO']\n",
        "data = rawData.drop(['FLAG', 'CONS_NO'], axis=1)\n",
        "\n",
        "dropIndex = data[data.duplicated()].index  # duplicates drop\n",
        "data = data.drop(dropIndex, axis=0)\n",
        "infoData = infoData.drop(dropIndex, axis=0)\n",
        "\n",
        "zeroIndex = data[(data.sum(axis=1) == 0)].index  # zero rows drop\n",
        "data = data.drop(zeroIndex, axis=0)\n",
        "infoData = infoData.drop(zeroIndex, axis=0)\n",
        "\n",
        "# data.columns = pd.to_datetime(data.columns)  # columns reindexing according to dates\n",
        "# data = data.reindex(sorted(data.columns), axis=1)\n",
        "cols = data.columns\n",
        "\n",
        "data.reset_index(inplace=True, drop=True)  # index sorting\n",
        "infoData.reset_index(inplace=True, drop=True)\n",
        "\n",
        "data = data.interpolate(method='linear', limit=2,  # filling NaN values\n",
        "                        limit_direction='both', axis=0).fillna(0)\n",
        "\n",
        "for i in range(data.shape[0]):  # outliers treatment\n",
        "    m = data.loc[i].mean()\n",
        "    st = data.loc[i].std()\n",
        "    data.loc[i] = data.loc[i].mask(data.loc[i] > (m + 3 * st), other=m + 3 * st)\n",
        "\n",
        "data.to_csv(r'visualization.csv', index=False, header=True)  # preprocessed data without scaling\n",
        "# data.to_csv('/content/drive/MyDrive/python/visulaization.csv', index=False)\n",
        "\n",
        "scale = MinMaxScaler()\n",
        "scaled = scale.fit_transform(data.values.T).T\n",
        "mData = pd.DataFrame(data=scaled, columns=data.columns)\n",
        "print(mData)\n",
        "preprData = pd.concat([infoData, mData], axis=1, sort=False)  # Back to initial format\n",
        "print(preprData)\n",
        "preprData.to_csv(r'preprocessedR.csv', index=False, header=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NQ7RilD2evcP"
      },
      "source": [
        "# Model Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ehz7FMEif5-w"
      },
      "source": [
        "## Model Paramaneters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SuraedggfQ3F"
      },
      "outputs": [],
      "source": [
        "tf.random.set_seed(1234)\n",
        "epochs_number = 1  # number of epochs for the neural networks\n",
        "test_set_size = 0.1  # percentage of the test size comparing to the whole dataset\n",
        "oversampling_flag = 0  # set to 1 to over-sample the minority class\n",
        "oversampling_percentage = 0.2  # percentage of the minority class after the oversampling comparing to majority class"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kczYlVGpf-im"
      },
      "source": [
        "## Data Loader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_MU4s3T9etXE"
      },
      "outputs": [],
      "source": [
        "# Definition of functions\n",
        "def read_data():\n",
        "    rawData = pd.read_csv('preprocessedR.csv')\n",
        "\n",
        "    # Setting the target and dropping the unnecessary columns\n",
        "    y = rawData[['FLAG']]\n",
        "    X = rawData.drop(['FLAG', 'CONS_NO'], axis=1)\n",
        "\n",
        "    print('Normal Consumers:                    ', y[y['FLAG'] == 0].count()[0])\n",
        "    print('Consumers with Fraud:                ', y[y['FLAG'] == 1].count()[0])\n",
        "    print('Total Consumers:                     ', y.shape[0])\n",
        "    print(\"Classification assuming no fraud:     %.2f\" % (y[y['FLAG'] == 0].count()[0] / y.shape[0] * 100), \"%\")\n",
        "\n",
        "    # columns reindexing according to dates\n",
        "    # X.columns = pd.to_datetime(X.columns)\n",
        "    # X = X.reindex(X.columns, axis=1)\n",
        "\n",
        "    # Splitting the dataset into training set and test set\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y['FLAG'], test_size=test_set_size, random_state=0)\n",
        "    print(\"Test set assuming no fraud:           %.2f\" % (y_test[y_test == 0].count() / y_test.shape[0] * 100), \"%\\n\")\n",
        "\n",
        "    # Oversampling of minority class to encounter the imbalanced learning\n",
        "    if oversampling_flag == 1:\n",
        "        over = SMOTE(sampling_strategy=oversampling_percentage, random_state=0)\n",
        "        X_train, y_train = over.fit_resample(X_train, y_train)\n",
        "        print(\"Oversampling statistics in training set: \")\n",
        "        print('Normal Consumers:                    ', y_train[y_train == 0].count())\n",
        "        print('Consumers with Fraud:                ', y_train[y_train == 1].count())\n",
        "        print(\"Total Consumers                      \", X_train.shape[0])\n",
        "\n",
        "    return X_train, X_test, y_train, y_test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7k5tX38cgB3P"
      },
      "source": [
        "## Models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jjfQDU6DgFBW"
      },
      "source": [
        "### Artificial Neural Network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ft91wf8Yfg2x"
      },
      "outputs": [],
      "source": [
        "def ANN(X_train, X_test, y_train, y_test):\n",
        "    print('Artificial Neural Network:')\n",
        "    # for i in range(4,100,3):\n",
        "    #     print(\"Epoch:\",i)\n",
        "\n",
        "    # Model creation\n",
        "    model = Sequential()\n",
        "    model.add(Dense(1000, input_dim=1034, activation='relu'))\n",
        "    model.add(Dense(100, activation='relu'))\n",
        "    model.add(Dense(100, activation='relu'))\n",
        "    model.add(Dense(100, activation='relu'))\n",
        "    model.add(Dense(10, activation='relu'))\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "    model.compile(loss=keras.losses.binary_crossentropy,\n",
        "                  optimizer='adam',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    # model.fit(X_train, y_train, validation_split=0, epochs=i, shuffle=True, verbose=0)\n",
        "    model.fit(X_train, y_train, validation_split=0, epochs=epochs_number, shuffle=True, verbose=1)\n",
        "    prediction =(model.predict(X_test) > 0.5).astype(\"int32\")\n",
        "    model.summary()\n",
        "    results(y_test, prediction)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VFu0OZssgdXC"
      },
      "source": [
        "### 1D - Convolutional Neural Network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bSWG40AsfnTy"
      },
      "outputs": [],
      "source": [
        "def CNN1D(X_train, X_test, y_train, y_test):\n",
        "    print('1D - Convolutional Neural Network:')\n",
        "\n",
        "    # Transforming the dataset into tensors\n",
        "    X_train = X_train.to_numpy().reshape(X_train.shape[0], X_train.shape[1], 1)\n",
        "    X_test = X_test.to_numpy().reshape(X_test.shape[0], X_test.shape[1], 1)\n",
        "\n",
        "    # Model creation\n",
        "    model = Sequential()\n",
        "    model.add(Conv1D(100, kernel_size=7, input_shape=(1034, 1), activation='relu'))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(100, activation='relu'))\n",
        "    model.add(Dense(100, activation='relu'))\n",
        "    model.add(Dense(64, activation='relu'))\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "    model.compile(loss=keras.losses.binary_crossentropy,\n",
        "                  optimizer='adam',\n",
        "                  metrics=['accuracy'])\n",
        "    #model.load_weights('/content/drive/MyDrive/Power_Theft_Detection/model_weights.h5')\n",
        "\n",
        "    # model.fit(X_train, y_train, epochs=1, validation_split=0.1, shuffle=False, verbose=1)\n",
        "    model.fit(X_train, y_train, epochs=epochs_number, validation_split=0, shuffle=False, verbose=1)\n",
        "    prediction = (model.predict(X_test) > 0.5).astype(\"int32\")\n",
        "    model.summary()\n",
        "    results(y_test, prediction)\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V5v4MAGhgfk_"
      },
      "source": [
        "### 2D - Convolutional Neural Network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5WnxaGlBfqdk"
      },
      "outputs": [],
      "source": [
        "def CNN2D(X_train, X_test, y_train, y_test):\n",
        "    print('2D - Convolutional Neural Network:')\n",
        "\n",
        "    # Transforming every row of the train set into a 2D array and then into a tensor\n",
        "    n_array_X_train = X_train.to_numpy()\n",
        "    n_array_X_train_extended = np.hstack((n_array_X_train, np.zeros(\n",
        "        (n_array_X_train.shape[0], 2))))  # adding two empty columns in order to make the number of columns\n",
        "    # an exact multiple of 7\n",
        "    week = []\n",
        "    for i in range(n_array_X_train_extended.shape[0]):\n",
        "        a = np.reshape(n_array_X_train_extended[i], (-1, 7, 1))\n",
        "        week.append(a)\n",
        "    X_train_reshaped = np.array(week)\n",
        "\n",
        "    # Transforming every row of the train set into a 2D array and then into a tensor\n",
        "    n_array_X_test = X_test.to_numpy()  # X_test to 2D - array\n",
        "    n_array_X_train_extended = np.hstack((n_array_X_test, np.zeros((n_array_X_test.shape[0], 2))))\n",
        "    week2 = []\n",
        "    for i in range(n_array_X_train_extended.shape[0]):\n",
        "        b = np.reshape(n_array_X_train_extended[i], (-1, 7, 1))\n",
        "        week2.append(b)\n",
        "    X_test_reshaped = np.array(week2)\n",
        "\n",
        "    input_shape = (1, 148, 7, 1)  # input shape of the tensor\n",
        "\n",
        "    # Model creation\n",
        "    model = Sequential()\n",
        "    model.add(Conv2D(kernel_size=(7, 3), filters=32, input_shape=input_shape[1:], activation='relu',\n",
        "                     data_format='channels_last'))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(100, activation='relu'))\n",
        "    model.add(Dense(100, activation='relu'))\n",
        "    model.add(Dense(64, activation='relu'))\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "    model.compile(loss=keras.losses.binary_crossentropy,\n",
        "                  optimizer='adam',\n",
        "                  metrics=['accuracy'])\n",
        "    # model.summary()\n",
        "    #     model.fit(X_train_reshaped, y_train, validation_split=0.1, epochs=i, shuffle=False, verbose=0)\n",
        "    model.fit(X_train_reshaped, y_train, validation_split=0.1, epochs=epochs_number, shuffle=False, verbose=1)\n",
        "\n",
        "    # prediction = model.predict_classes(X_test)\n",
        "    prediction = (model.predict(X_test_reshaped) > 0.5).astype(\"int32\")\n",
        "    model.summary()\n",
        "    results(y_test, prediction)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OrDdBYnigixK"
      },
      "source": [
        "### Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hrQYurJgfuJp"
      },
      "outputs": [],
      "source": [
        "def LR(X_train, X_test, y_train, y_test):\n",
        "    print('Logistic Regression:')\n",
        "    '''\n",
        "    # Parameters selection\n",
        "    param_grid = {'C': [0.1,1,10,100],'solver': ['newton-cg', 'lbfgs']}\n",
        "    grid = GridSearchCV(LogisticRegression(max_iter=1000,random_state=0), param_grid=param_grid, n_jobs=-1)\n",
        "    grid.fit(X_train, y_train)\n",
        "    df = pd.DataFrame(grid.cv_results_)\n",
        "    print(df[['param_C', 'param_solver', 'mean_test_score', 'rank_test_score']])\n",
        "    '''\n",
        "    model = LogisticRegression(C=1000, max_iter=1000, n_jobs=-1, solver='newton-cg')\n",
        "    model.fit(X_train, y_train)\n",
        "    prediction = model.predict(X_test)\n",
        "    results(y_test, prediction)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "viRnOgf2glpa"
      },
      "source": [
        "### Decision Tree"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hT9-tgRAfwvK"
      },
      "outputs": [],
      "source": [
        "def DT(X_train, X_test, y_train, y_test):\n",
        "    print('Decision Tree:')\n",
        "    model = DecisionTreeClassifier(random_state=0)\n",
        "    model.fit(X_train, y_train)\n",
        "    prediction = model.predict(X_test)\n",
        "    results(y_test, prediction)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kHICI6i2gpg0"
      },
      "source": [
        "### Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HPkOgHOUfyY_"
      },
      "outputs": [],
      "source": [
        "def RF(X_train, X_test, y_train, y_test):\n",
        "    print('Random Forest:')\n",
        "    '''\n",
        "    # Parameters selection\n",
        "    param_grid = {'n_estimators':[10,100,1000]}\n",
        "    grid = GridSearchCV(RandomForestClassifier(random_state=0), param_grid=param_grid, n_jobs=-1)\n",
        "    grid.fit(X_train, y_train)\n",
        "    df = pd.DataFrame(grid.cv_results_)\n",
        "    print(df[['param_criterion', 'mean_test_score', 'rank_test_score']])\n",
        "    '''\n",
        "\n",
        "    model = RandomForestClassifier(n_estimators=100, min_samples_leaf=1, max_features='auto',  # max_depth=10,\n",
        "                                   random_state=0, n_jobs=-1)\n",
        "    model.fit(X_train, y_train)\n",
        "    prediction = model.predict(X_test)\n",
        "    results(y_test, prediction)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gjlgK9HngrVL"
      },
      "source": [
        "### Support Vector Machine"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aLYrCqqwZL9j"
      },
      "outputs": [],
      "source": [
        "def SVM(X_train, X_test, y_train, y_test):\n",
        "    model = SVC(random_state=0)\n",
        "    model.fit(X_train, y_train)\n",
        "    prediction = model.predict(X_test)\n",
        "    results(y_test, prediction)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bVPC2anjF60A"
      },
      "source": [
        "### XGBoost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lk34dLr1qvC4"
      },
      "outputs": [],
      "source": [
        "def XGB(X_train, X_test, y_train, y_test):\n",
        "    # import XGBClassifier\n",
        "    from xgboost import XGBClassifier\n",
        "\n",
        "    # declare parameters\n",
        "    params = {\n",
        "                'objective':'binary:logistic',\n",
        "                'max_depth': 4,\n",
        "                'alpha': 10,\n",
        "                'learning_rate': 1.0,\n",
        "                'n_estimators':100\n",
        "            }\n",
        "    # instantiate the classifier\n",
        "    model = XGBClassifier(**params)\n",
        "    model.fit(X_train, y_train)\n",
        "    prediction = model.predict(X_test)\n",
        "    results(y_test, prediction)\n",
        "    return model\n",
        "# fit the classifier to the training data\n",
        "# xgb_clf.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xYxvZN0Rguxs"
      },
      "source": [
        "## Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YQXf92KUfdyL"
      },
      "outputs": [],
      "source": [
        "def results(y_test, prediction):\n",
        "    print(\"Accuracy\", 100 * accuracy_score(y_test, prediction))\n",
        "    print(\"RMSE:\", mean_squared_error(y_test, prediction, squared=False))\n",
        "    print(\"MAE:\", mean_absolute_error(y_test, prediction))\n",
        "    print(\"F1:\", 100 * precision_recall_fscore_support(y_test, prediction)[2])\n",
        "    print(\"AUC:\", 100 * roc_auc_score(y_test, prediction))\n",
        "    print(confusion_matrix(y_test, prediction), \"\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y7SJsfLVgxKN"
      },
      "source": [
        "# Main"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WFIUf-QqfZJl",
        "outputId": "d2b47885-b252-4323-9122-737a6c47fb9d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Normal Consumers:                     33741\n",
            "Consumers with Fraud:                 3383\n",
            "Total Consumers:                      37124\n",
            "Classification assuming no fraud:     90.89 %\n",
            "Test set assuming no fraud:           90.98 %\n",
            "\n",
            "Accuracy 90.51979531376246\n",
            "RMSE: 0.30789941029884327\n",
            "MAE: 0.09480204686237544\n",
            "F1: [95.0070922   6.38297872]\n",
            "AUC: 51.36179670033491\n",
            "[[3349   29]\n",
            " [ 323   12]] \n",
            "\n"
          ]
        }
      ],
      "source": [
        "# ----Main----\n",
        "X_train, X_test, y_train, y_test = read_data()\n",
        "\n",
        "# Uncomment any model to test\n",
        "# ANN(X_train, X_test, y_train, y_test)\n",
        "# model = CNN1D(X_train, X_test, y_train, y_test)\n",
        "# model = CNN2D(X_train, X_test, y_train, y_test)\n",
        "# RF(X_train, X_test, y_train, y_test)\n",
        "# LR(X_train, X_test, y_train, y_test)\n",
        "# DT(X_train, X_test, y_train, y_test)\n",
        "# SVM(X_train, X_test, y_train, y_test)\n",
        "model = XGB(X_train, X_test, y_train, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ndRJaPxjkKYy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "93c35551-c09e-4dd8-dbaa-78a86770e860"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [03:04:54] WARNING: /workspace/src/c_api/c_api.cc:1240: Saving into deprecated binary model format, please consider using `json` or `ubj`. Model format will default to JSON in XGBoost 2.2 if not specified.\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        }
      ],
      "source": [
        "# Assuming 'model' is your trained Keras model\n",
        "model.save_model('trained_model.h5')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Prediction Functions**"
      ],
      "metadata": {
        "id": "Lm6v9W5M-7Mq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Process Input"
      ],
      "metadata": {
        "id": "F2pjWW5z_EX-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_input(input_data):\n",
        "    # rawData = input_data\n",
        "    '''\n",
        "    infoData = pd.DataFrame()\n",
        "    infoData['FLAG'] = rawData['FLAG']\n",
        "    infoData['CONS_NO'] = rawData['CONS_NO']\n",
        "    data = rawData.drop(['FLAG', 'CONS_NO'], axis=1)\n",
        "    '''\n",
        "    data = input_data\n",
        "\n",
        "    dropIndex = data[data.duplicated()].index  # duplicates drop\n",
        "    data = data.drop(dropIndex, axis=0)\n",
        "    # infoData = infoData.drop(dropIndex, axis=0)\n",
        "\n",
        "    zeroIndex = data[(data.sum(axis=1) == 0)].index  # zero rows drop\n",
        "    data = data.drop(zeroIndex, axis=0)\n",
        "    # infoData = infoData.drop(zeroIndex, axis=0)\n",
        "\n",
        "    # data.columns = pd.to_datetime(data.columns)  # columns reindexing according to dates\n",
        "    # data = data.reindex(sorted(data.columns), axis=1)\n",
        "    cols = data.columns\n",
        "\n",
        "    data.reset_index(inplace=True, drop=True)  # index sorting\n",
        "    # infoData.reset_index(inplace=True, drop=True)\n",
        "\n",
        "    data = data.interpolate(method='linear', limit=2,  # filling NaN values\n",
        "                            limit_direction='both', axis=0).fillna(0)\n",
        "\n",
        "    for i in range(data.shape[0]):  # outliers treatment\n",
        "        m = data.loc[i].mean()\n",
        "        st = data.loc[i].std()\n",
        "        data.loc[i] = data.loc[i].mask(data.loc[i] > (m + 3 * st), other=m + 3 * st)\n",
        "\n",
        "    scale = MinMaxScaler()\n",
        "    scaled = scale.fit_transform(data.values.T).T\n",
        "    mData = pd.DataFrame(data=scaled, columns=data.columns)\n",
        "    preprData = pd.concat([infoData, mData], axis=1, sort=False)  # Back to initial format\n",
        "\n",
        "\n",
        "    # Setting the target and dropping the unnecessary columns\n",
        "    y = preprData[['FLAG']]\n",
        "    X = preprData.drop(['FLAG', 'CONS_NO'], axis=1)\n",
        "\n",
        "    # columns reindexing according to dates\n",
        "    # X.columns = pd.to_datetime(X.columns)\n",
        "    # X = X.reindex(X.columns, axis=1)\n",
        "\n",
        "    # Splitting the dataset into training set and test set\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y['FLAG'], test_size=0.5, random_state=0)\n",
        "    return  X_test, y_test"
      ],
      "metadata": {
        "id": "fFkWzfwgrnno"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Predict"
      ],
      "metadata": {
        "id": "Wr8nNyCi_LeQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform prediction\n",
        "def predict(input_data, model):\n",
        "    prediction = model.predict(xgb.DMatrix(input_data.values))\n",
        "    binary_prediction = (prediction > 0.5).astype(\"int32\")\n",
        "    return binary_prediction"
      ],
      "metadata": {
        "id": "_R6kE32p8__z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load Model"
      ],
      "metadata": {
        "id": "EZvKglmO_dbC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import xgboost as xgb\n",
        "print(xgb.__version__)\n",
        "# Load the model\n",
        "model = xgb.Booster()\n",
        "model.load_model('trained_model.h5')"
      ],
      "metadata": {
        "id": "YqA7J-fe7o-b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "18d0b6a4-6321-4c1c-e46d-f07280574ff9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.0.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Take sample inputs"
      ],
      "metadata": {
        "id": "GF-gdJUU_5fG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/drive/MyDrive/Power_Theft_Detection/Dataset/data.csv')"
      ],
      "metadata": {
        "id": "vWijkKS07std"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.iloc[:, -30:]"
      ],
      "metadata": {
        "id": "wY4nJ0zb_FLF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.columns.values[-30:] = [f\"day{i}\" for i in range(1, 31)]"
      ],
      "metadata": {
        "id": "5fxg9Nw8Aebz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sampled_df = df.sample(n=3000)"
      ],
      "metadata": {
        "id": "3jAjhoow-_Rg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sampled_df.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uYIyYEFlEkQP",
        "outputId": "bc0bb897-54d0-4853-b289-0c8964a8cb15"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3000, 30)"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sampled_df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "eD2sF0yHJhCs",
        "outputId": "2dc5730a-e133-49d7-8721-856f425879a4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        day1   day2   day3   day4   day5   day6   day7   day8   day9  day10  \\\n",
              "5711    5.33   4.79  10.98  11.64   6.85   6.36   7.06   7.63   8.58   6.28   \n",
              "37827   0.03   0.17   0.08   0.40   0.09   0.21   0.58   0.94   0.59   0.24   \n",
              "28972   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   \n",
              "15212  85.60  69.04  15.62  24.64  31.08  32.78  36.27  21.98  34.09  41.52   \n",
              "41447   5.32   5.74   5.59   4.82   4.82   5.58   4.34   5.36   4.12   4.67   \n",
              "\n",
              "       ...  day21  day22  day23  day24  day25  day26  day27  day28  day29  \\\n",
              "5711   ...   5.33   7.33   3.79  11.06   8.72   8.88   5.14   5.62   5.69   \n",
              "37827  ...   0.21   0.14   0.29   0.14   0.21   0.10   0.28   0.10   0.15   \n",
              "28972  ...   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   \n",
              "15212  ...  15.67  14.93  30.39  26.28  54.24  57.86  53.56  50.92  43.72   \n",
              "41447  ...   4.94   3.78   5.53   4.58   5.54   5.39   5.67   6.06   5.63   \n",
              "\n",
              "       day30  \n",
              "5711    5.45  \n",
              "37827   0.15  \n",
              "28972   0.00  \n",
              "15212  32.84  \n",
              "41447   5.44  \n",
              "\n",
              "[5 rows x 30 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-615cb884-5a78-4f19-9fc3-e8c88123f5f8\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>day1</th>\n",
              "      <th>day2</th>\n",
              "      <th>day3</th>\n",
              "      <th>day4</th>\n",
              "      <th>day5</th>\n",
              "      <th>day6</th>\n",
              "      <th>day7</th>\n",
              "      <th>day8</th>\n",
              "      <th>day9</th>\n",
              "      <th>day10</th>\n",
              "      <th>...</th>\n",
              "      <th>day21</th>\n",
              "      <th>day22</th>\n",
              "      <th>day23</th>\n",
              "      <th>day24</th>\n",
              "      <th>day25</th>\n",
              "      <th>day26</th>\n",
              "      <th>day27</th>\n",
              "      <th>day28</th>\n",
              "      <th>day29</th>\n",
              "      <th>day30</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>5711</th>\n",
              "      <td>5.33</td>\n",
              "      <td>4.79</td>\n",
              "      <td>10.98</td>\n",
              "      <td>11.64</td>\n",
              "      <td>6.85</td>\n",
              "      <td>6.36</td>\n",
              "      <td>7.06</td>\n",
              "      <td>7.63</td>\n",
              "      <td>8.58</td>\n",
              "      <td>6.28</td>\n",
              "      <td>...</td>\n",
              "      <td>5.33</td>\n",
              "      <td>7.33</td>\n",
              "      <td>3.79</td>\n",
              "      <td>11.06</td>\n",
              "      <td>8.72</td>\n",
              "      <td>8.88</td>\n",
              "      <td>5.14</td>\n",
              "      <td>5.62</td>\n",
              "      <td>5.69</td>\n",
              "      <td>5.45</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37827</th>\n",
              "      <td>0.03</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.08</td>\n",
              "      <td>0.40</td>\n",
              "      <td>0.09</td>\n",
              "      <td>0.21</td>\n",
              "      <td>0.58</td>\n",
              "      <td>0.94</td>\n",
              "      <td>0.59</td>\n",
              "      <td>0.24</td>\n",
              "      <td>...</td>\n",
              "      <td>0.21</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.29</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.21</td>\n",
              "      <td>0.10</td>\n",
              "      <td>0.28</td>\n",
              "      <td>0.10</td>\n",
              "      <td>0.15</td>\n",
              "      <td>0.15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28972</th>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>...</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15212</th>\n",
              "      <td>85.60</td>\n",
              "      <td>69.04</td>\n",
              "      <td>15.62</td>\n",
              "      <td>24.64</td>\n",
              "      <td>31.08</td>\n",
              "      <td>32.78</td>\n",
              "      <td>36.27</td>\n",
              "      <td>21.98</td>\n",
              "      <td>34.09</td>\n",
              "      <td>41.52</td>\n",
              "      <td>...</td>\n",
              "      <td>15.67</td>\n",
              "      <td>14.93</td>\n",
              "      <td>30.39</td>\n",
              "      <td>26.28</td>\n",
              "      <td>54.24</td>\n",
              "      <td>57.86</td>\n",
              "      <td>53.56</td>\n",
              "      <td>50.92</td>\n",
              "      <td>43.72</td>\n",
              "      <td>32.84</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41447</th>\n",
              "      <td>5.32</td>\n",
              "      <td>5.74</td>\n",
              "      <td>5.59</td>\n",
              "      <td>4.82</td>\n",
              "      <td>4.82</td>\n",
              "      <td>5.58</td>\n",
              "      <td>4.34</td>\n",
              "      <td>5.36</td>\n",
              "      <td>4.12</td>\n",
              "      <td>4.67</td>\n",
              "      <td>...</td>\n",
              "      <td>4.94</td>\n",
              "      <td>3.78</td>\n",
              "      <td>5.53</td>\n",
              "      <td>4.58</td>\n",
              "      <td>5.54</td>\n",
              "      <td>5.39</td>\n",
              "      <td>5.67</td>\n",
              "      <td>6.06</td>\n",
              "      <td>5.63</td>\n",
              "      <td>5.44</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 30 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-615cb884-5a78-4f19-9fc3-e8c88123f5f8')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-615cb884-5a78-4f19-9fc3-e8c88123f5f8 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-615cb884-5a78-4f19-9fc3-e8c88123f5f8');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-0ff03bc8-910b-464d-8bee-feffc23be999\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-0ff03bc8-910b-464d-8bee-feffc23be999')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-0ff03bc8-910b-464d-8bee-feffc23be999 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "sampled_df"
            }
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Generate Predictions"
      ],
      "metadata": {
        "id": "fZEvLHZkAbuu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "inputData = pd.read_csv('/content/drive/MyDrive/Power_Theft_Detection/input_data.csv')\n",
        "preprocessed_input, labels = preprocess_input(inputData)\n",
        "predictions = predict(preprocessed_input, model)"
      ],
      "metadata": {
        "id": "Y5IEQojeAfD7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GmENseu7Cn7s",
        "outputId": "8c0e3fc0-66f7-448b-b6ef-ef1cc25d3795"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "18562"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "reuc2qlnAnm7",
        "outputId": "c9216372-ee9c-4440-d6fe-017cd0725575"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 0, ..., 0, 0, 0], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results(labels, predictions)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_EEM8mjxEezC",
        "outputId": "4c9c7d26-5acb-42c5-85b2-f138f769f22b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy 90.6852709837302\n",
            "RMSE: 0.3052004098337648\n",
            "MAE: 0.09314729016269799\n",
            "F1: [95.11512926  0.        ]\n",
            "AUC: 50.0\n",
            "[[16833     0]\n",
            " [ 1729     0]] \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## pickle file"
      ],
      "metadata": {
        "id": "1ngkNeAWmhqx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### create a pickle file using serialization\n",
        "#import pickle\n",
        "#pickle_out = open(\"classifier.pkl\",\"wb\")\n",
        "#pickle.dump(classifier, pickle_out)\n",
        "#pickle_out.close()"
      ],
      "metadata": {
        "id": "MofSaGEXmkKC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "m2qpMxv1nhSN"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "jjfQDU6DgFBW",
        "V5v4MAGhgfk_",
        "OrDdBYnigixK",
        "viRnOgf2glpa",
        "kHICI6i2gpg0",
        "gjlgK9HngrVL",
        "bVPC2anjF60A"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}